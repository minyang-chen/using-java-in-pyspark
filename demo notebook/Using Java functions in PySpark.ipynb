{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967913de",
   "metadata": {},
   "source": [
    "# Calling Java function in PySpark  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a3f8b",
   "metadata": {},
   "source": [
    "### Download and transfer java jar file from repository to spark\n",
    "\n",
    "Note: recommend: place java udf jar under spark jars folder. otherwise require restart jupyter kernel before calling java functions due dynamic loading require java jars in spark classpath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e352c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from web link directly and put under user-libs folder\n",
    "# !wget https://my-repository-link/PySparkJavaUDFDemo-jar-with-dependencies.jar.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da65c7",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dabb8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import SparkConf, SparkContext, SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('PySpark-Java-UDF-Test') \\\n",
    "    .config('spark.executor.memory', '4gb') \\\n",
    "    .config(\"spark.cores.max\", \"1\") \\\n",
    "    .config(\"spark.jars\", \"./shared/PySparkJavaUDFDemo-jar-with-dependencies.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", (\"./shared/PySparkJavaUDFDemo-jar-with-dependencies.jar\")) \\\n",
    "    .config(\"spark.executor.extraClassPath\", (\"./shared/PySparkJavaUDFDemo-jar-with-dependencies.jar\")) \\\n",
    "    .config(\"spark.executor.extraLibraryPath\", \"./shared/\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "## or Do add jar file\n",
    "spark.sparkContext.addFile(\"./shared/PySparkJavaUDFDemo-jar-with-dependencies.jar\")\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99640a28",
   "metadata": {},
   "source": [
    "## create test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430bb3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- ssn: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+----------+------+------+---+-----+----+--------+---------+\n",
      "|first_name|middle_name|last_name|ssn       |gender|salary|age|zip  |race|latitude|longitude|\n",
      "+----------+-----------+---------+----------+------+------+---+-----+----+--------+---------+\n",
      "|James     |           |Smith    |3663636636|M     |53000 |20 |96941|1   |1.0     |2.0      |\n",
      "|Michael   |Rose       |         |4028840288|M     |84000 |31 |96970|2   |3.0     |4.0      |\n",
      "|Robert    |           |Williams |4211442114|M     |94000 |16 |96940|3   |5.0     |6.0      |\n",
      "|Maria     |Anne       |Jones    |3919239192|F     |64000 |22 |96960|4   |7.0     |8.0      |\n",
      "|Jen       |Mary       |Brown    |5919233911|F     |79000 |39 |96939|5   |0.0     |9.0      |\n",
      "+----------+-----------+---------+----------+------+------+---+-----+----+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,DoubleType\n",
    "data2 = [\n",
    "    (\"James\",\"\",\"Smith\",\"3663636636\",\"M\",53000,20,96941,\"1\",1.0,2.0),\n",
    "    (\"Michael\",\"Rose\",\"\",\"4028840288\",\"M\",84000,31,96970,\"2\",3.0,4.0),\n",
    "    (\"Robert\",\"\",\"Williams\",\"4211442114\",\"M\",94000,16,96940,\"3\",5.0,6.0),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"3919239192\",\"F\",64000,22,96960,\"4\",7.0,8.0),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"5919233911\",\"F\",79000,39,96939,\"5\",0.0,9.0)\n",
    "  ]\n",
    "schema = StructType([ \\\n",
    "    StructField(\"first_name\",StringType(),True), \\\n",
    "    StructField(\"middle_name\",StringType(),True), \\\n",
    "    StructField(\"last_name\",StringType(),True), \\\n",
    "    StructField(\"ssn\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True), \\\n",
    "    StructField(\"age\", IntegerType(), True), \\\n",
    "    StructField(\"zip\", StringType(), True), \\\n",
    "    StructField(\"race\", StringType(), True), \\\n",
    "    StructField(\"latitude\", DoubleType(), True), \\\n",
    "    StructField(\"longitude\", DoubleType(), True)                                            \n",
    "  ])\n",
    "df1 = spark.createDataFrame(data=data2,schema=schema)\n",
    "df1.printSchema()\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f10ab",
   "metadata": {},
   "source": [
    "## A. Call Java Method Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac21d680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932156789321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'9321$$$$$$$$'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the static java function with spark\n",
    "ssn=\"123456789321\"\n",
    "spark.sparkContext._jvm.pyspark.java.udf.JavaTransformFunctions.transformFieldValueEnding(ssn, 4,'$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06c250",
   "metadata": {},
   "source": [
    "## B. Call the java UDF with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22dfba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the java UDF with spark\n",
    "spark.udf.registerJavaFunction(\"transform_fieldvalue\", \"pyspark.java.udf.JavaFieldTransformUDF\", T.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cf87ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+----------+------+------+---+-----+----+--------+---------+----------+\n",
      "|first_name|middle_name|last_name|       ssn|gender|salary|age|  zip|race|latitude|longitude|  ssn_hide|\n",
      "+----------+-----------+---------+----------+------+------+---+-----+----+--------+---------+----------+\n",
      "|     James|           |    Smith|3663636636|     M| 53000| 20|96941|   1|     1.0|      2.0|36********|\n",
      "|   Michael|       Rose|         |4028840288|     M| 84000| 31|96970|   2|     3.0|      4.0|88********|\n",
      "|    Robert|           | Williams|4211442114|     M| 94000| 16|96940|   3|     5.0|      6.0|14********|\n",
      "|     Maria|       Anne|    Jones|3919239192|     F| 64000| 22|96960|   4|     7.0|      8.0|92********|\n",
      "|       Jen|       Mary|    Brown|5919233911|     F| 79000| 39|96939|   5|     0.0|      9.0|11********|\n",
      "+----------+-----------+---------+----------+------+------+---+-----+----+--------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe call it using F.expr:\n",
    "(\n",
    "    df1.withColumn(\"ssn_hide\", F.expr(\"transform_fieldvalue(ssn, 2,'*')\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9960cc5",
   "metadata": {},
   "source": [
    "## C. Call the java UDF in SQL Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2587afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+-----+\n",
      "|first_name|last_name|       ssn|  zip|\n",
      "+----------+---------+----------+-----+\n",
      "|     James|    Smith|6636******|41***|\n",
      "|   Michael|         |0288******|70***|\n",
      "|    Robert| Williams|2114******|40***|\n",
      "|     Maria|    Jones|9192******|60***|\n",
      "|       Jen|    Brown|3911******|39***|\n",
      "+----------+---------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark SQL \n",
    "df1.createOrReplaceTempView(\"people\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        first_name, last_name, transform_fieldvalue(ssn, 4,'*') as ssn, transform_fieldvalue(zip, 2,'*') as zip\n",
    "    FROM people\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c33cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
